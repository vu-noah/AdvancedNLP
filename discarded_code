# feature extraction

def extract_features(doc):
    """
    Extract feature dictionaries for every word in a stanza.Document object, store them in lists, zip and return them.
    :param stanza.Document doc: a stanza.Document object containing processed text
    :return: XXX
    """
    # create lists to store feature dictionaries in
    categorical_feature_dictionaries = []
    binary_feature_dictionaries = []

    for sentence in doc.sentences:

        # print(sentence)
        # constituent_tree = sentence.constituency
        # # print(help(constituent_tree))
        # # print(constituent_tree.label)
        # print(constituent_tree.children[0].children)
        # # print(constituent_tree.pretty_print())
        # # print(constituent_tree.leaf_labels())
        # # print(constituent_tree.depth())
        #
        # # constituents = str(constituent_tree.pretty_print()).split('\n')
        # # print(constituents)
        #
        # constituents = str(constituent_tree.children[0].children).replace(',', '')
        # constituents = constituents.replace('(', '', 1)
        # print(constituents)
        #
        # open_counter = 0
        # close_counter = 0
        # constituent = ''
        # for character in constituents:
        #     constituent = constituent + character
        #     if character == '(':
        #         open_counter += 1
        #     if character == ')':
        #         close_counter += 1
        #     if open_counter == close_counter:
        #         print(constituent)
        #         constituent = ''
        #         open_counter = 0
        #         close_counter = 0

        # constituents = []
        # def break_down_constituents(constituent_structure):
        #     for child in constituent_structure.children:
        #         constituent = str(child).split(')')
        #         constituents.append(constituent)
        #         break_down_constituents(child)
        #
        # break_down_constituents(constituent_tree.children[0])
        # for el in constituents:
        #     print(el)

        for word in sentence.words:

            # create feature dictionaries for the word
            categorical_feature_dictionary = {'token': word.text.lower()}
            binary_feature_dictionary = {}

            ...